# ===================================================================================
# ğŸ“Œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ ë° 20ëŒ€ ê³ ê°êµ° ì´íƒˆ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ìš”ì•½
# 1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
# 2ï¸âƒ£ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
# 3ï¸âƒ£ ì£¼ìš” íŠ¹ì„± ë¶„ì„ ë° ì‹œê°í™”
# 4ï¸âƒ£ 20ëŒ€(Age=1) ê³ ê° ì¤‘ì  ë¶„ì„
# 5ï¸âƒ£ - ì§€ì—­(ResidenceCity, WorkCity)ë³„ ì´íƒˆë¥  ë¶„ì„
# 6ï¸âƒ£ - ì‚¬ìš© íŒ¨í„´ë³„ ì´íƒˆ ë¶„ì„
# 7ï¸âƒ£ - ì„±ë³„(Gender)ë³„ ì´íƒˆë¥  ë¹„êµ
# ===================================================================================

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
X_train = pd.read_csv('train/X_train.csv')
X_val = pd.read_csv('train/X_val.csv')
X_test = pd.read_csv('train/X_test.csv')
y_train = pd.read_csv('train/y_train.csv').squeeze()
y_val = pd.read_csv('train/y_val.csv').squeeze()
y_test = pd.read_csv('train/y_test.csv').squeeze()

# ë¬¸ìì—´ ë°ì´í„° í™•ì¸ ë° ë³€í™˜ (ë°œê¸‰íšŒì›ë²ˆí˜¸)
def preprocess_features(df):
    for col in df.select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
    return df

X_train = preprocess_features(X_train)
X_val = preprocess_features(X_val)
X_test = preprocess_features(X_test)

# ë°ì´í„° ì •ê·œí™” (Standardization)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train_scaled, y_train)

# ê²€ì¦ ë°ì´í„° í‰ê°€
y_val_pred = model.predict(X_val_scaled)
val_accuracy = accuracy_score(y_val, y_val_pred)

print("Validation Accuracy:", val_accuracy)
print("\nConfusion Matrix (Validation):\n", confusion_matrix(y_val, y_val_pred))
print("\nClassification Report (Validation):\n", classification_report(y_val, y_val_pred))

# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
y_test_pred = model.predict(X_test_scaled)
test_accuracy = accuracy_score(y_test, y_test_pred)

print("Test Accuracy:", test_accuracy)
print("\nConfusion Matrix (Test):\n", confusion_matrix(y_test, y_test_pred))
print("\nClassification Report (Test):\n", classification_report(y_test, y_test_pred))

print("Logistic Regression model trained and evaluated successfully.")

########### ìƒì„¸ ë¶„ì„ ë° ì‹œê°í™” ##############
# 1. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
feature_importance = np.abs(model.coef_[0])
features = X_train.columns
sorted_idx = np.argsort(feature_importance)[::-1]

plt.figure(figsize=(30, 20))
plt.bar(range(len(features)), feature_importance[sorted_idx], align="center")
plt.xticks(range(len(features)), features[sorted_idx], rotation=90)
plt.title("Feature Importance (Logistic Regression)")
plt.show()

# 2. ROC-AUC ë¶„ì„
y_test_prob = model.predict_proba(X_test_scaled)[:, 1]
roc_auc = roc_auc_score(y_test, y_test_prob)
fpr, tpr, _ = roc_curve(y_test, y_test_prob)

# 3. ROC Curve ì‹œê°í™”
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

# 5. í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ - ê· í˜•
# print(y_train.value_counts(normalize=True))
# ê²°ê³¼
# EXIT
# 1    0.500102
# 0    0.499898
# Name: proportion, dtype: float64


# 6. ì—°ë ¹ë³„ ì´íƒˆë¥  ë¶„ì„
# X_trainì— y_train ì¶”ê°€í•˜ì—¬ ì—°ë ¹ë³„ ë¶„ì„í•˜ê¸°
X_train['EXIT'] = y_train

age_exit_rate = X_train.groupby('Age')['EXIT'].agg(['mean', 'count']).reset_index()
age_exit_rate.columns = ['Age', 'ExitRate', 'CustomerCount']

# ê·¸ë˜í”„ ì‹œê°í™”
plt.figure(figsize=(12, 6))
sns.barplot(x='Age', y='ExitRate', data=age_exit_rate, palette='Blues_d', hue='Age', dodge=False, legend=False)

plt.title('Exit Rate by Age Group', fontsize=16)
plt.xlabel('Age Group', fontsize=12)
plt.ylabel('Exit Rate', fontsize=12)
plt.ylim(0, 1)  # ì´íƒˆë¥  ë²”ìœ„ (0~1)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.legend([], [], frameon=False)  # ë²”ë¡€ ì œê±°
plt.show()

# ì „ì²´ ê³ ê° í‰ê·  ì´íƒˆë¥  ê³„ì‚° - 50%
overall_exit_rate = X_train['EXIT'].mean()
print(f"Overall Exit Rate: {overall_exit_rate:.2f}")

# 20ëŒ€(ì—°ë ¹=1) ê³ ê° í‰ê·  ì´íƒˆë¥  ê³„ì‚° - 57%
age_20s_exit_rate = X_train[X_train['Age'] == 1]['EXIT'].mean()
print(f"Exit Rate for Age Group 20s (Age=1): {age_20s_exit_rate:.2f}")


############ 20ëŒ€ ê³ ê° ì¤‘ì  ë¶„ì„ ###############
age_20s_data = X_train[X_train['Age'] == 1]  # Ageê°€ 1ì¸ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ì—¬ 20ëŒ€ ê³ ê° ë°ì´í„° ìƒì„±
age_20s_data['EXIT'] = y_train  # 20ëŒ€ ê³ ê°ì˜ ì´íƒˆ ì—¬ë¶€ë¥¼ ë°ì´í„°ì— ì¶”ê°€

# i. 20ëŒ€ ê³ ê°ì˜ ì´íƒˆ ì—¬ë¶€ì— ë”°ë¥¸ UsageAmountCategory ë¶„í¬ ë¹„êµ
usage_columns = ['201809_UsageAmountCategory', '201808_UsageAmountCategory', '201807_UsageAmountCategory']  # ë¶„ì„ ëŒ€ìƒ ì—´ ì§€ì •

for col in usage_columns:
    plt.figure(figsize=(10, 6))
    sns.countplot(
        data=age_20s_data,  # ë°ì´í„°
        x=col,  # Xì¶• UsageAmountCategory ì§€ì •
        hue='EXIT',  # ì´íƒˆ ì—¬ë¶€ì— ë”°ë¼ ìƒ‰ìƒ êµ¬ë¶„
        palette='Set2',  # ì‹œê°í™”ë¥¼ ìœ„í•œ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„¤ì •
        order=sorted(age_20s_data[col].unique())  # UsageAmountCategory ê°’ì˜ ìˆœì„œë¥¼ ì§€ì •í•˜ì—¬ ì •ë ¬
    )
    plt.title(f"Distribution of {col} by EXIT for Age 20s")  # ì œëª©
    plt.xlabel("Usage Amount Category")  # Xì¶• ë ˆì´ë¸”
    plt.ylabel("Count")  # Yì¶• ë ˆì´ë¸”
    plt.xticks(
        ticks=range(len(age_20s_data[col].unique())),  # ì¹´í…Œê³ ë¦¬ ìˆ˜ì— ë§ê²Œ í‹± ì„¤ì •
        labels=sorted(age_20s_data[col].unique())  # ì¹´í…Œê³ ë¦¬ ì´ë¦„ìœ¼ë¡œ í‹± ë ˆì´ë¸” ì„¤ì •
    )
    plt.legend(title="EXIT", labels=["Retained (0)", "Churned (1)"])  # ë²”ë¡€ ì„¤ì •
    plt.show()

# ii. ì´ìš©ê¸ˆì•¡ëŒ€ë³„ ì´íƒˆë¥  ê³„ì‚° ë° ì‹œê°í™”
for col in usage_columns:
    churn_rate = age_20s_data.groupby(col)['EXIT'].mean().reset_index()  # UsageAmountCategory ë³„ í‰ê·  ì´íƒˆë¥  ê³„ì‚°

    plt.figure(figsize=(10, 6))
    sns.barplot(
        data=churn_rate,  # ë°ì´í„° ì†ŒìŠ¤
        x=col,  # Xì¶• UsageAmountCategory ì—´ ì§€ì •
        y='EXIT',  # Yì¶•ì— ì´íƒˆë¥  ì§€ì •
        palette='coolwarm'  # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„¤ì •
    )
    plt.title(f"Churn Rate by {col} for Age 20s")  # ì œëª©
    plt.xlabel("Usage Amount Category")  # Xì¶• ë ˆì´ë¸”
    plt.ylabel("Churn Rate")  # Yì¶• ë ˆì´ë¸”
    plt.ylim(0, 1)  # Yì¶• ë²”ìœ„ ì„¤ì •
    plt.show()


# iii. 20ëŒ€ ê³ ê° ì£¼ìš” ë³€ìˆ˜ì™€ ì´íƒˆ ì—¬ë¶€ ê°„ ìƒê´€ê´€ê³„
correlations = age_20s_data.corr()['EXIT'].sort_values(ascending=False)
print("Correlations with EXIT for Age Group 20s:")
print(correlations)
# 201809_UsageAmountCategory    0.870465
# 201808_UsageAmountCategory    0.856354
# 201807_UsageAmountCategory    0.832290
# WorkCity_None                 0.100457

# iv. VIP ë“±ê¸‰ì— ë”°ë¥¸ 20ëŒ€ ê³ ê°ì˜ ì´íƒˆë¥  ì‹œê°í™” - 6, 7ì˜ ì´íƒˆë¥  ë†’ìŒ
plt.figure(figsize=(10, 6))
vip_exit_rate = age_20s_data.groupby('VIPGradeCode')['EXIT'].mean().reset_index()
#VIP ë“±ê¸‰ë³„ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ê³ , ê° ê·¸ë£¹ ë‚´ì—ì„œ EXIT ì—´ì˜ í‰ê· ê°’ì„ ê³„ì‚° (í•´ë‹¹ ê·¸ë£¹ì˜ ì´íƒˆë¥ )
sns.barplot(x='VIPGradeCode', y='EXIT', data=vip_exit_rate, palette='Blues_d', hue='VIPGradeCode')
plt.title('Exit Rate by VIP Grade for Age 20s')
plt.xlabel('VIP Grade')
plt.ylabel('Exit Rate')
plt.ylim(0, 1)
plt.show()

# ---------------------------------------------------------------------------------------------

# i. ì§€ì—­ ë³€ìˆ˜ì™€ ì´íƒˆë¥  ê´€ê³„ ë¶„ì„

# 1. ResidenceCityì™€ EXITì˜ ê´€ê³„ ë¶„ì„
residence_columns = [col for col in age_20s_data.columns if col.startswith('ResidenceCity')]
residence_exit_rate = pd.DataFrame()

# ResidenceCity ë³„ ì´íƒˆë¥  ê³„ì‚°
for col in residence_columns:
    city_name = col.replace('ResidenceCity_', '')  # ë³€ìˆ˜ëª…ì—ì„œ ì§€ì—­ ì´ë¦„ ì¶”ì¶œ
    city_data = age_20s_data[age_20s_data[col] == 1]  # í•´ë‹¹ ì§€ì—­ì˜ ë°ì´í„° í•„í„°ë§
    exit_rate = city_data['EXIT'].mean() if not city_data.empty else 0  # ì´íƒˆë¥  ê³„ì‚°
    residence_exit_rate = pd.concat(
        [residence_exit_rate, pd.DataFrame({'City': [city_name], 'ExitRate': [exit_rate]})]
    )

# ResidenceCity ì´íƒˆë¥  ì‹œê°í™”
plt.figure(figsize=(12, 8))
sns.barplot(data=residence_exit_rate, x='City', y='ExitRate', palette='coolwarm', hue='City')
plt.title('Exit Rate by Residence City for Age 20s')
plt.xlabel('Residence City')
plt.ylabel('Exit Rate')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

# 2. WorkCityì™€ EXITì˜ ê´€ê³„ ë¶„ì„
work_columns = [col for col in age_20s_data.columns if col.startswith('WorkCity')]
work_exit_rate = pd.DataFrame()

# WorkCityë³„ ì´íƒˆë¥  ê³„ì‚°
for col in work_columns:
    city_name = col.replace('WorkCity_', '')  # ë³€ìˆ˜ëª…ì—ì„œ ì§€ì—­ ì´ë¦„ ì¶”ì¶œ
    city_data = age_20s_data[age_20s_data[col] == 1]  # í•´ë‹¹ ì§€ì—­ì˜ ë°ì´í„° í•„í„°ë§
    exit_rate = city_data['EXIT'].mean() if not city_data.empty else 0  # ì´íƒˆë¥  ê³„ì‚°
    work_exit_rate = pd.concat(
        [work_exit_rate, pd.DataFrame({'City': [city_name], 'ExitRate': [exit_rate]})]
    )

# WorkCity ì´íƒˆë¥  ì‹œê°í™”
plt.figure(figsize=(12, 8))
sns.barplot(data=work_exit_rate, x='City', y='ExitRate', palette='coolwarm', hue='City')
plt.title('Exit Rate by Work City for Age 20s')
plt.xlabel('Work City')
plt.ylabel('Exit Rate')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

# ii. ê±°ì£¼ì§€ ê·¼ë¬´ì§€ ë‹¤ë¥¸ ê²½ìš°ì˜ ì´íƒˆë¥  ë¶„ì„

# ê±°ì£¼ì§€ì™€ ê·¼ë¬´ì§€ ë³€ìˆ˜ í•„í„°ë§
residence_columns = [col for col in X_train.columns if col.startswith('ResidenceCity_')]
work_columns = [col for col in X_train.columns if col.startswith('WorkCity_')]

# 20ëŒ€ ê³ ê° ë°ì´í„° í•„í„°ë§
age_20s_data = X_train[X_train['Age'] == 1].copy()
age_20s_data['EXIT'] = y_train  # ì´íƒˆ ì—¬ë¶€ ì¶”ê°€

# ê±°ì£¼ì§€ì™€ ê·¼ë¬´ì§€ ë¹„êµ: ë™ì¼ ì—¬ë¶€ í™•ì¸
def residence_work_match(row):
    for res_col, work_col in zip(residence_columns, work_columns):
        if row[res_col] == 1 and row[work_col] == 1:
            return 'Same'
    return 'Different'

# "Same"ê³¼ "Different" ë ˆì´ë¸” ì¶”ê°€
age_20s_data['Residence_Work_Match'] = age_20s_data.apply(residence_work_match, axis=1)

# ì´íƒˆë¥  ê³„ì‚°
exit_rate = age_20s_data.groupby('Residence_Work_Match')['EXIT'].mean().reset_index()
exit_rate.columns = ['Residence_Work_Match', 'Exit_Rate']

# ì‹œê°í™” - ë³„ ì°¨ì´ ì—†ìŒ
plt.figure(figsize=(8, 6))
sns.barplot(data=exit_rate, x='Residence_Work_Match', y='Exit_Rate', palette='coolwarm')
plt.title('Exit Rate by Residence and Work Match for Age 20s')
plt.xlabel('Residence and Work Match')
plt.ylabel('Exit Rate')
plt.ylim(0, 1)
plt.show()

# ìƒì„¸ ë°ì´í„° ì¶œë ¥
same_match_exit = age_20s_data[age_20s_data['Residence_Work_Match'] == 'Same']['EXIT'].mean()
different_match_exit = age_20s_data[age_20s_data['Residence_Work_Match'] == 'Different']['EXIT'].mean()

print("\nDetailed Exit Rates:")
print(f"Same Residence and Work: {same_match_exit:.2f}")
print(f"Different Residence and Work: {different_match_exit:.2f}")


# 7. 20ëŒ€ ê³ ê° ì¤‘, ì—°ì†ì ìœ¼ë¡œ ì‚¬ìš©ëŸ‰ì´ ê°ì†Œí•˜ëŠ” ê³ ê°êµ°ì´ ì´íƒˆí•  ìœ„í—˜ì´ ë†’ì€ì§€ í™•ì¸

# 20ëŒ€ ê³ ê° ë°ì´í„° í•„í„°ë§
age_20s_data = X_train[X_train['Age'] == 1]
age_20s_data['EXIT'] = y_train  # 20ëŒ€ ê³ ê°ì˜ ì´íƒˆ ì—¬ë¶€ë¥¼ ì¶”ê°€

# UsageAmountCategory ì—´ ì •ì˜
usage_columns = ['201809_UsageAmountCategory', '201808_UsageAmountCategory', '201807_UsageAmountCategory']

# ì›”ë³„ ì‚¬ìš©ëŸ‰ ë³€í™” íŒ¨í„´ ë¶„ì„
# ì—°ì†ì ìœ¼ë¡œ ì‚¬ìš©ëŸ‰ì´ ê°ì†Œí•˜ëŠ” ê³ ê° ìˆ˜ë¥¼ ê³„ì‚°
def count_consecutive_decreases(row):
    decreases = 0
    for i in range(len(usage_columns) - 1):
        if row[usage_columns[i]] > row[usage_columns[i + 1]]:  # ê°ì†Œ ì—¬ë¶€
            decreases += 1
    return decreases

age_20s_data['Consecutive_Decreases'] = age_20s_data.apply(count_consecutive_decreases, axis=1)

# ì—°ì†ì ìœ¼ë¡œ ì‚¬ìš©ëŸ‰ì´ ê°ì†Œí•˜ëŠ” ê³ ê°êµ° ë¶„ë¦¬
decrease_group = age_20s_data[age_20s_data['Consecutive_Decreases'] == len(usage_columns) - 1]  # ëª¨ë“  ì›”ì—ì„œ ê°ì†Œ
non_decrease_group = age_20s_data[age_20s_data['Consecutive_Decreases'] < len(usage_columns) - 1]  # ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°

# ì´íƒˆë¥  ê³„ì‚°
churn_rate_decrease = decrease_group['EXIT'].mean()  # ê°ì†Œ ê·¸ë£¹ì˜ ì´íƒˆë¥ 
churn_rate_non_decrease = non_decrease_group['EXIT'].mean()  # ë¹„ê°ì†Œ ê·¸ë£¹ì˜ ì´íƒˆë¥ 

print(f"Churn Rate for Decrease Group: {churn_rate_decrease:.2f}")
print(f"Churn Rate for Non-Decrease Group: {churn_rate_non_decrease:.2f}")

# ì‹œê°í™”
plt.figure(figsize=(10, 6))
sns.barplot(
    x=['Decrease Group', 'Non-Decrease Group'],
    y=[churn_rate_decrease, churn_rate_non_decrease],
    palette='coolwarm'
)
plt.title('Churn Rate by Usage Decrease Pattern for Age 20s')
plt.ylabel('Churn Rate')
plt.ylim(0, 1)
plt.show()

# 8. 20ëŒ€ - ì„±ë³„ì— ë”°ë¥¸ ì´íƒˆìœ¨ - ê±°ì˜ ì°¨ì´ ì—†ìŒ

# ì„±ë³„ì— ë”°ë¥¸ ì´íƒˆë¥  ë¶„ì„
gender_exit_rate = age_20s_data.groupby('GenderCode')['EXIT'].mean().reset_index()  # ì„±ë³„ë³„ í‰ê·  ì´íƒˆë¥  ê³„ì‚°
gender_exit_rate['Gender'] = gender_exit_rate['GenderCode'].map({1: 'Male', 2: 'Female'})  # ì„±ë³„ ì½”ë“œ ë§¤í•‘

# ì´íƒˆë¥  ì‹œê°í™”
plt.figure(figsize=(8, 5))
sns.barplot(x='Gender', y='EXIT', data=gender_exit_rate, palette='Set2')
plt.title('Exit Rate by Gender for Age 20s')
plt.xlabel('Gender')
plt.ylabel('Exit Rate')
plt.ylim(0, 1)  # Yì¶• ë²”ìœ„ ì„¤ì • (0ì—ì„œ 1 ì‚¬ì´)
plt.show()

# ì„±ë³„ë³„ ì´íƒˆë¥  ì¶œë ¥
print("Gender-wise Exit Rates:")
print(gender_exit_rate[['Gender', 'EXIT']])