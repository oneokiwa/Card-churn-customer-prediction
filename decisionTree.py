# ===================================================================================
# ğŸ“Œ ê²°ì • íŠ¸ë¦¬ ëª¨ë¸ í•™ìŠµ ë° ì”ì•¡ ì´íƒˆ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ìš”ì•½
# 1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
# 2ï¸âƒ£ ê²°ì • íŠ¸ë¦¬ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
# 3ï¸âƒ£ íŠ¸ë¦¬ êµ¬ì¡° ì‹œê°í™”
# 4ï¸âƒ£ ì£¼ìš” íŠ¹ì„±(Feature Importance) ë¶„ì„
# 5ï¸âƒ£ 201809_Balance_B0M íŠ¹ì„± ì‹¬ì¸µ ë¶„ì„
# 6ï¸âƒ£ ì‚¬ìš©ê¸ˆì•¡ëŒ€(UsageAmountCategory)ì™€ ì”ì•¡(Balance_B0M) ê°„ ê´€ê³„ ë¶„ì„
# ===================================================================================

import pandas as pd
import numpy as np
import shap
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
X_train = pd.read_csv('train/X_train.csv')
X_val = pd.read_csv('train/X_val.csv')
X_test = pd.read_csv('train/X_test.csv')
y_train = pd.read_csv('train/y_train.csv').squeeze()
y_val = pd.read_csv('train/y_val.csv').squeeze()
y_test = pd.read_csv('train/y_test.csv').squeeze()

# ë¬¸ìì—´ ë° ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬
def preprocess_features(df):
    label_encoders = {}
    for col in df.select_dtypes(include=['object']).columns:  # ë¬¸ìì—´ ë°ì´í„° ì—´ í™•ì¸
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])  # ë¬¸ìì—´ ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜
        label_encoders[col] = le  # ê° ì—´ì˜ ì¸ì½”ë” ì €ì¥
    return df, label_encoders

X_train, label_encoders = preprocess_features(X_train)
X_val, _ = preprocess_features(X_val)  # ê²€ì¦ ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
X_test, _ = preprocess_features(X_test)  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬

# DecisionTreeClassifier ëª¨ë¸ ìƒì„±
model = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)
model.fit(X_train, y_train)  # ëª¨ë¸ í•™ìŠµ

# ê²€ì¦ ë°ì´í„°ë¡œ ì„±ëŠ¥ í™•ì¸
y_val_pred = model.predict(X_val)
print("Validation Accuracy:", accuracy_score(y_val, y_val_pred))
print("\nConfusion Matrix (Validation):\n", confusion_matrix(y_val, y_val_pred))
print("\nClassification Report (Validation):\n", classification_report(y_val, y_val_pred))

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… í‰ê°€
y_test_pred = model.predict(X_test)
print("Test Accuracy:", accuracy_score(y_test, y_test_pred))
print("\nConfusion Matrix (Test):\n", confusion_matrix(y_test, y_test_pred))
print("\nClassification Report (Test):\n", classification_report(y_test, y_test_pred))

# 6. íŠ¸ë¦¬ ì‹œê°í™”
plt.figure(figsize=(20, 10))
plot_tree(model, feature_names=X_train.columns, class_names=['Retained', 'Churned'], filled=True, fontsize=10)
plt.title('Decision Tree Visualization')
plt.show()

############### ì‹¬ì¸µ ë¶„ì„ ë° ì‹œê°í™” ###############
# 1. Feature Importance ë¶„ì„
feature_importances = model.feature_importances_
importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# ìƒìœ„ 5ê°œ ë³€ìˆ˜ ì‹œê°í™”
plt.figure(figsize=(20, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df.head(), palette='viridis', hue='Importance')
plt.title('Top 5 Feature Importances')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

# 1. ë¶„í¬ ë¶„ì„: ì”ì•¡ ë¶„í¬ì™€ ì´íƒˆ ì—¬ë¶€ì— ë”°ë¥¸ ì°¨ì´
plt.figure(figsize=(20, 6))
sns.histplot(X_train['201809_Balance_B0M'], kde=True, color='blue', label='Overall')
sns.histplot(X_train[y_train == 1]['201809_Balance_B0M'], kde=True, color='red', label='Churned')
sns.histplot(X_train[y_train == 0]['201809_Balance_B0M'], kde=True, color='green', label='Retained')
plt.title('Distribution of 201809_Balance_B0M by EXIT')
plt.xlabel('201809_Balance_B0M')
plt.ylabel('Density')
plt.legend()
plt.show()

# 2. ìƒê´€ê´€ê³„ ë¶„ì„: ì£¼ìš” ë…ë¦½ë³€ìˆ˜ì™€ EXIT ê°„ ìƒê´€ì„±
correlation = X_train['201809_Balance_B0M'].corr(y_train)
print(f"Correlation between 201809_Balance_B0M and EXIT: {correlation:.4f}")

# 3. ì”ì•¡ êµ¬ê°„ë³„ ì´íƒˆë¥  ë¶„ì„ - ì”ì•¡ì´ ì ì„ìˆ˜ë¡ ì´íƒˆë¥ ì´ ë†’ë‹¤.
X_train['EXIT'] = y_train

# ì”ì•¡ êµ¬ê°„ ì •ì˜ (low: ë‚®ìŒ, medium: ì¤‘ê°„, high: ë†’ìŒ)
def categorize_balance(balance):
    if balance < 500000:  # ì”ì•¡ì´ 50ë§Œ ì› ë¯¸ë§Œ
        return 'Low'
    elif balance < 2000000:  # ì”ì•¡ì´ 50ë§Œ ì› ì´ìƒ 200ë§Œ ì› ë¯¸ë§Œ
        return 'Medium'
    else:  # ì”ì•¡ì´ 200ë§Œ ì› ì´ìƒ
        return 'High'

# Balance_B0M êµ¬ê°„ ì¶”ê°€
X_train['Balance_Category'] = X_train['201807_Balance_B0M'].apply(categorize_balance)

# ì”ì•¡ êµ¬ê°„ë³„ ì´íƒˆë¥  ê³„ì‚°
balance_exit_rate = X_train.groupby('Balance_Category')['EXIT'].mean().reset_index()

# ì‹œê°í™”
plt.figure(figsize=(8, 6))
sns.barplot(
    data=balance_exit_rate,
    x='Balance_Category',
    y='EXIT',
    palette='coolwarm'
)
plt.title('Churn Rate by Balance Category', fontsize=16)
plt.xlabel('Balance Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.ylim(0, 1)
plt.show()

print("Churn Rate by Balance Category:")
print(balance_exit_rate)


# 4. UsageAmountCategoryì™€ Balance_B0M ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ê³„ì‚°
correlation = X_train[['201809_UsageAmountCategory', '201809_Balance_B0M']].corr().iloc[0, 1]
print(f"Correlation between UsageAmountCategory and Balance_B0M: {correlation:.4f}")

# i. ì‚°ì ë„ë¥¼ ì´ìš©í•œ ì‹œê°í™”
plt.figure(figsize=(10, 6))
sns.scatterplot(
    x='201809_UsageAmountCategory',
    y='201809_Balance_B0M',
    data=X_train,
    alpha=0.7
)
plt.title('Scatter Plot: UsageAmountCategory vs. Balance_B0M')
plt.xlabel('UsageAmountCategory')
plt.ylabel('Balance_B0M')
plt.show()

# ii. íˆíŠ¸ë§µì„ ì´ìš©í•œ ìƒê´€ê´€ê³„ ì‹œê°í™”
plt.figure(figsize=(8, 6))
sns.heatmap(
    X_train[['201809_UsageAmountCategory', '201809_Balance_B0M']].corr(),
    annot=True,
    cmap='coolwarm',
    cbar=True,
    fmt='.2f'
)
plt.title('Correlation Heatmap: UsageAmountCategory vs. Balance_B0M')
plt.show()